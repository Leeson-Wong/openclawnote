# æ·±åº¦è°ƒç ” - LangChain æ ¸å¿ƒæœºåˆ¶

## ğŸ¯ è°ƒç ”æ—¶é—´
- **å¼€å§‹æ—¶é—´**: 2026-02-03 12:05
- **é¢„è®¡æ—¶é—´**: 20 åˆ†é’Ÿ
- **è°ƒç ”å¯¹è±¡**: LangChain (https://github.com/langchain-ai/langchain)

---

## ğŸ” è°ƒç ”é‡ç‚¹

### 1. LCEL (LangChain Expression Language)
- è¡¨è¾¾å¼è¯­æ³•å’Œè§£æ
- ç±»å‹å®‰å…¨
- æµæ§åˆ¶ï¼ˆé“¾å¼ã€å¹¶è¡Œã€åˆ†æ”¯ï¼‰
- å·¥å…·é›†æˆ
- æ‡’æ€§æ±‚å€¼

### 2. Stateful Agents (çŠ¶æ€å›¾ Agents)
- çŠ¶æ€å®šä¹‰å’Œç®¡ç†
- çŠ¶æ€è½¬æ¢è§„åˆ™
- æ¶ˆæ¯ä¼ é€’æœºåˆ¶
- å›¾æ‰§è¡Œå¼•æ“
- å¯è§‚æµ‹æ€§å’Œè¿½è¸ª

### 3. Agent Executor
- å·¥å…·è°ƒç”¨æœºåˆ¶
- å‚æ•°è§£æ
- ç»“æœè¿”å›
- é”™è¯¯å¤„ç†
- æµç¨‹æ§åˆ¶

---

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µåˆ†æ

### LCEL æ ¸å¿ƒç»„ä»¶

#### 1. è¡¨è¾¾å¼ç±»å‹
```python
from langchain.prompts import ChatPromptTemplate

# å­—ç¬¦ä¸²è¡¨è¾¾å¼
prompt = ChatPromptTemplate.from_template("Tell me a {topic}")
chain = prompt | model

# å¯¹è±¡è¡¨è¾¾å¼
from langchain_core.runnables import ConfigurableField
agent = Agent(
    name="Agent",
    role="{role}",
    goal="{goal}",
    backstory="{backstory}",
    verbose=True
)
```

#### 2. æ“ä½œç¬¦
- `|` (pipe): å·¦åˆ°å³ä¼ é€’
- `.` (dot): è°ƒç”¨é“¾ä¸­çš„ä¸‹ä¸€ä¸ª runnable
- `RunnablePassthrough()`: ä¸ä¿®æ”¹è¾“å…¥ç›´æ¥ä¼ é€’
- `RunnableParallel()`: å¹¶è¡Œæ‰§è¡Œ
- `RunnableBranch()`: æ¡ä»¶åˆ†æ”¯
- `RunnableMap()`: æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒè·¯å¾„

#### 3. å·¥å…·é›†æˆ
```python
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

@tool
def search(query: str) -> str:
    """æœç´¢å·¥å…·"""
    return f"æœç´¢ç»“æœ: {query}"

# åœ¨è¡¨è¾¾å¼ä¸­ä½¿ç”¨
agent = ChatOpenAI(model="gpt-4")
agent_with_tools = agent.bind_tools([search])
```

### Stateful Agents æ ¸å¿ƒç»„ä»¶

#### 1. çŠ¶æ€å®šä¹‰
```python
from typing import TypedDict, Annotated, Sequence
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import BaseMessage

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    current_step: Annotated[str, "start"]
    result: Annotated[str, ""]
    research_summary: Annotated[str, ""]
    analysis: Annotated[str, ""]
```

#### 2. èŠ‚ç‚¹ï¼ˆNodesï¼‰
```python
def research_node(state: AgentState):
    """ç ”ç©¶èŠ‚ç‚¹"""
    # è°ƒç”¨ç ”ç©¶å·¥å…·
    return {
        "research_summary": state.get("research_summary", "") + " ç ”ç©¶å®Œæˆ"
    }

def analysis_node(state: AgentState):
    """åˆ†æèŠ‚ç‚¹"""
    # è°ƒç”¨åˆ†æå·¥å…·
    return {
        "analysis": state.get("analysis", "") + " åˆ†æå®Œæˆ"
    }

def decision_node(state: AgentState):
    """å†³ç­–èŠ‚ç‚¹"""
    # æ•´åˆç ”ç©¶ç»“æœå’Œåˆ†æç»“æœ
    research = state.get("research_summary", "")
    analysis = state.get("analysis", "")
    return {
        "result": f"åŸºäºç ”ç©¶ {research} å’Œåˆ†æ {analysis} çš„å†³ç­–"
    }
```

#### 3. è¾¹ï¼ˆEdgesï¼‰
```python
# çŠ¶æ€å›¾å®šä¹‰
graph = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
graph.add_node("research", research_node)
graph.add_node("analysis", analysis_node)
graph.add_node("decision", decision_node)

# æ·»åŠ è¾¹ï¼ˆå®šä¹‰è½¬æ¢æµç¨‹ï¼‰
graph.add_edge(START, "research")
graph.add_edge("research", "analysis")
graph.add_edge("analysis", "decision")
graph.add_edge("decision", END)

# ç¼–è¯‘å›¾
app = graph.compile()
```

### Agent Executor æ ¸å¿ƒæœºåˆ¶

#### 1. å·¥å…·å®šä¹‰å’Œæ³¨å†Œ
```python
from langchain_core.tools import tool
from typing import Optional

@tool
def web_search(query: str, max_results: int = 5) -> str:
    """æœç´¢ç½‘ç»œä¿¡æ¯"""
    # å®ç°æœç´¢é€»è¾‘
    return f"æœç´¢åˆ° {max_results} ä¸ªç»“æœå…³äº {query}"

@tool
def analyze_data(data: str) -> str:
    """åˆ†ææ•°æ®"""
    # å®ç°åˆ†æé€»è¾‘
    return f"æ•°æ®åˆ†æ: {data}"

# è‡ªåŠ¨æ³¨å†Œåˆ° agent
agent = ChatOpenAI(model="gpt-4")
agent_with_tools = agent.bind_tools([web_search, analyze_data])
```

#### 2. å·¥å…·è°ƒç”¨æµç¨‹
```python
# å·¥å…·è°ƒç”¨å™¨
class ToolCallProcessor:
    def process_tool_call(self, tool_name: str, tool_args: dict) -> str:
        # æŸ¥æ‰¾å·¥å…·
        tool = self.get_tool(tool_name)
        if not tool:
            return f"å·¥å…· {tool_name} æœªæ‰¾åˆ°"
        
        # è§£æå‚æ•°
        try:
            result = tool.invoke(tool_args)
            return str(result)
        except Exception as e:
            return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def get_tool(self, tool_name: str) -> Optional[Tool]:
        # ä»å·¥å…·æ³¨å†Œè¡¨è·å–å·¥å…·
        return self.tool_registry.get(tool_name)
```

---

## ğŸ¯ ä¸æˆ‘ä»¬è®¾è®¡çš„å…³è”

### Agent 1: Gateway Agent
```python
# Gateway Agent çš„ LCEL å®ç°
from langchain_core.prompts import ChatPromptTemplate

gateway_prompt = ChatPromptTemplate.from_template(
    """ä½ æ˜¯ä¸€ä¸ªé€šä¿¡ç½‘å…³ï¼Œè´Ÿè´£ï¼š
1. è§£æç”¨æˆ·è¾“å…¥
2. ç†è§£ç”¨æˆ·æ„å›¾
3. è·¯ç”±åˆ°åˆé€‚çš„ agent

ç”¨æˆ·è¾“å…¥: {input}
"""
)

gateway_chain = gateway_prompt | ChatOpenAI(model="gpt-4")

# ç±»ä¼¼æˆ‘ä»¬çš„ ConnectionManager
```

### Agent 2: Coordinator Agent
```python
# Coordinator Agent çš„ Stateful Agent å®ç°
from langgraph.graph import StateGraph, START, END

class CoordinatorState(TypedDict):
    messages: list
    tasks: list
    results: dict
    progress: float

def task_decompose_node(state: CoordinatorState):
    # ç±»ä¼¼æˆ‘ä»¬çš„ TaskDecomposer
    return {
        "tasks": decompose_task(state.get("user_task", ""))
    }

def agent_allocate_node(state: CoordinatorState):
    # ç±»ä¼¼æˆ‘ä»¬çš„ AgentAllocator
    return {
        "agent_assignments": allocate_tasks_to_agents(state.get("tasks", []))
    }
```

### Agent 3: Execution Agent
```python
# Execution Agent çš„å·¥å…·è°ƒç”¨å®ç°
from langchain_core.tools import tool

@tool
def execute_code(code: str, language: str = "python") -> str:
    """æ‰§è¡Œä»£ç """
    # ç±»ä¼¼æˆ‘ä»¬çš„ CodeExecutor
    return execute_in_docker(code, language)

execution_agent = ChatOpenAI(model="gpt-4")
execution_agent = execution_agent.bind_tools([execute_code])
```

---

## ğŸ“Š å…³é”®å‘ç°

### 1. LCEL çš„ä¼˜åŠ¿
- **ç±»å‹å®‰å…¨**: TypeScript/Python ç±»å‹ç³»ç»Ÿç¡®ä¿ç±»å‹æ­£ç¡®
- **å¯ç»„åˆæ€§**: è¡¨è¾¾å¼å¯ä»¥è½»æ¾ç»„åˆæˆå¤æ‚é“¾
- **å¯è¯»æ€§**: pipe æ“ä½œç¬¦è®©ä»£ç æµç¨‹æ¸…æ™°
- **å¯è°ƒè¯•**: æ¯ä¸ªæ­¥éª¤éƒ½å¯ä»¥å•ç‹¬æµ‹è¯•

### 2. Stateful Agents çš„ä¼˜åŠ¿
- **å¯è§†åŒ–**: çŠ¶æ€å›¾å¯ä»¥å¯è§†åŒ–ï¼Œä¾¿äºç†è§£
- **çµæ´»æ€§**: çŠ¶æ€å’Œè½¬æ¢å¯ä»¥åŠ¨æ€è°ƒæ•´
- **å¯è§‚æµ‹**: å®Œæ•´çš„æ‰§è¡Œè½¨è¿¹è¿½è¸ª
- **å¯æ‰©å±•**: æ˜“äºæ·»åŠ æ–°çš„èŠ‚ç‚¹å’Œè¾¹

### 3. å·¥å…·ç³»ç»Ÿçš„ä¼˜åŠ¿
- **ç»Ÿä¸€æ¥å£**: æ‰€æœ‰å·¥å…·ä½¿ç”¨ç›¸åŒçš„ `@tool` è£…é¥°å™¨
- **è‡ªåŠ¨æ–‡æ¡£**: å·¥å…·æè¿°è‡ªåŠ¨ç”Ÿæˆç”¨äº LLM
- **ç±»å‹å®‰å…¨**: å‚æ•°ç±»å‹é€šè¿‡ Python ç±»å‹æç¤ºå®šä¹‰
- **æ˜“äºé›†æˆ**: æ–°å·¥å…·å¯ä»¥è½»æ¾æ·»åŠ åˆ° agent

---

## ğŸš€ åº”ç”¨åˆ°æˆ‘ä»¬çš„è®¾è®¡

### Agent 1: Gateway Agent å®ç°
```python
# ä½¿ç”¨ LCEL å®ç° Gateway
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

gateway_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªé€šä¿¡ç½‘å…³å’Œåè®®å¤„ç†è€…ï¼Œè´Ÿè´£æ¥æ”¶æ‰€æœ‰ç”¨æˆ·è¯·æ±‚ï¼Œç†è§£æ„å›¾ï¼Œç„¶åè·¯ç”±åˆ°æ­£ç¡®çš„ agentã€‚"),
    ("user", "{input}")
])

gateway_parser = StrOutputParser()

gateway_chain = gateway_prompt | ChatOpenAI(model="gpt-4") | gateway_parser

# ç±»ä¼¼æˆ‘ä»¬çš„ ConnectionManager å’Œ HttpHandler
```

### Agent 2: Coordinator Agent å®ç°
```python
# ä½¿ç”¨ Stateful Agents å®ç° Coordinator
from langgraph.graph import StateGraph
from langgraph.prebuilt import create_react_agent

coordinator_app = create_react_agent(
    model=ChatOpenAI(model="gpt-4"),
    tools=[task_decompose_tool, agent_allocate_tool, progress_tracker_tool],
    state_modifier="messages"
)

# ç±»ä¼¼æˆ‘ä»¬çš„ CoordinatorAgent
```

---

## ğŸ“ ä¸‹ä¸€æ­¥ï¼šAutoGen æ·±åº¦ç ”ç©¶

### è°ƒç ”é‡ç‚¹
- å¯¹è¯é©±åŠ¨æ¶æ„
- GroupChat å®ç°æœºåˆ¶
- Agent æ¶ˆæ¯å¤„ç†
- å¯¹è¯åè°ƒç­–ç•¥

---

**è°ƒç ”çŠ¶æ€**: âœ… LangChain æ·±åº¦è°ƒç ”å®Œæˆï¼ˆ20 åˆ†é’Ÿï¼‰  
**ä¸‹ä¸€ç ”ç©¶**: AutoGenï¼ˆ20 åˆ†é’Ÿï¼‰  
**æ›´æ–°æ—¶é—´**: 2026-02-03 12:25
